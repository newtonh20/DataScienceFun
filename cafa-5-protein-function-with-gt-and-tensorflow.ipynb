{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CAFA 5 protein function Prediction with TensorFlow\n\nThis notebook walks you through how to train a DNN model using TensorFlow on the CAFA 5 protein function Prediction dataset made available for this competition.\n\nThe objective of the model is to predict the function(aka **GO term ID**) of a set of proteins based on their amino acid sequences and other data.\n\n\n**Note** : This notebook runs without any GPU. This is because enabling GPUs leaves less RAM memory on the VM and the submission step needs a lot of memory. One point where this would impact is when training the model. With CPU it will take around 2 minutes while on GPU it would take around 30 seconds.","metadata":{"papermill":{"duration":0.008875,"end_time":"2023-05-09T08:30:09.052999","exception":false,"start_time":"2023-05-09T08:30:09.044124","status":"completed"},"tags":[],"id":"pb-4zvGq1K4C"}},{"cell_type":"markdown","source":"## About the Data\n\n### Protein Sequence\n\nEach protein is composed of dozens or hundreds of amino acids that are linked sequentially. Each amino acid in the sequence may be represented by a one-letter or three-letter code. Thus the sequence of a protein is often notated as a string of letters.\n\n<img src=\"https://cityu-bioinformatics.netlify.app/img/tools/protein/pro_seq.png\" alt =\"Sequence.png\" style='width: 800px;' >\n\nImage source - [https://cityu-bioinformatics.netlify.app/](https://cityu-bioinformatics.netlify.app/too2/new_proteo/pro_seq/)\n\nThe `train_sequences.fasta` made available for this competitions, contains the sequences for proteins with annotations (labelled proteins).","metadata":{"papermill":{"duration":0.009266,"end_time":"2023-05-09T08:30:09.071132","exception":false,"start_time":"2023-05-09T08:30:09.061866","status":"completed"},"tags":[],"id":"B8H6QR-M1K4J"}},{"cell_type":"markdown","source":"# Gene Ontology\n\nWe can define the functional properties of a proteins using Gene Ontology(GO). Gene Ontology (GO) describes our understanding of the biological domain with respect to three aspects:\n1. Molecular Function (MF)\n2. Biological Process (BP)\n3. Cellular Component (CC)\n\nRead more about Gene Ontology [here](http://geneontology.org/docs/ontology-documentation).\n\nFile `train_terms.tsv` contains the list of annotated terms (ground truth) for the proteins in `train_sequences.fasta`. In `train_terms.tsv` the first column indicates the protein's UniProt accession ID (unique protein id), the second is the `GO Term ID`, and the third indicates in which ontology the term appears.","metadata":{"papermill":{"duration":0.008355,"end_time":"2023-05-09T08:30:09.08863","exception":false,"start_time":"2023-05-09T08:30:09.080275","status":"completed"},"tags":[],"id":"vYXassg_1K4L"}},{"cell_type":"markdown","source":"# Labels of the dataset\n\nThe objective of our model is to predict the terms (functions) of a protein sequence. One protein sequence can have many functions and can thus be classified into any number of terms. Each term is uniquely identified by a `GO Term ID`. Thus our model has to predict all the `GO Term ID`s for a protein sequence. This means that the task at hand is a multi-label classification problem.","metadata":{"id":"U1wpCeJH1K4M"}},{"cell_type":"markdown","source":"\n","metadata":{"papermill":{"duration":0.008308,"end_time":"2023-05-09T08:30:09.105539","exception":false,"start_time":"2023-05-09T08:30:09.097231","status":"completed"},"tags":[],"id":"M042PgfH1K4N"}},{"cell_type":"markdown","source":"# Protein embeddings for train and test data\n\nTo train a machine learning model we cannot use the alphabetical protein sequences in`train_sequences.fasta` directly. They have to be converted into a vector format. In this notebook, we will use embeddings of the protein sequences to train the model. You can think of protein embeddings to be similar to word embeddings used to train NLP models.\n<!-- Instead, to make calculations and data preparation easier we will use precalculated protein embeddings.\n -->\nProtein embeddings are a machine-friendly method of capturing the protein's structural and functional characteristics, mainly through its sequence. One approach is to train a custom ML model to learn the protein embeddings of the protein sequences in the dataset being used in this notebook. Since this dataset represents proteins using amino-acid sequences which is a standard approach, we can use any publicly available pre-trained protein embedding models to generate the embeddings.\n\nThere are a variety of protein embedding models. To make data preparation easier, we have used the precalculated protein embeddings created by [Sergei Fironov](https://www.kaggle.com/sergeifironov) using the Rost Lab's T5 protein language model in this notebook. The precalculated protein embeddings can be found [here](https://www.kaggle.com/datasets/sergeifironov/t5embeds). We have added this dataset to the notebook along with the dataset made available for the competition.\n\nTo add this to your enviroment, on the right side panel, click on `Add Data` and search for `t5embeds` (make sure that it's the correct [one](https://www.kaggle.com/datasets/sergeifironov/t5embeds)) and then click on the `+` beside it.\n\n**We'll start by introducing a variable that decides whether we prepare the training data cell by cell or if we do it all at once (for memory issues)**\n","metadata":{"papermill":{"duration":0.008548,"end_time":"2023-05-09T08:30:09.122603","exception":false,"start_time":"2023-05-09T08:30:09.114055","status":"completed"},"tags":[],"id":"tD6exQ-11K4N"}},{"cell_type":"code","source":"notebook_run = False","metadata":{"execution":{"iopub.status.busy":"2023-07-25T14:06:51.188674Z","iopub.execute_input":"2023-07-25T14:06:51.188961Z","iopub.status.idle":"2023-07-25T14:06:51.193619Z","shell.execute_reply.started":"2023-07-25T14:06:51.188933Z","shell.execute_reply":"2023-07-25T14:06:51.192703Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Import the Required Libraries","metadata":{"papermill":{"duration":0.009086,"end_time":"2023-05-09T08:30:09.140473","exception":false,"start_time":"2023-05-09T08:30:09.131387","status":"completed"},"tags":[],"id":"HeXcmUEb1K4O"}},{"cell_type":"code","source":"# Install required packages.\nimport os\nimport torch\nos.environ['TORCH'] = torch.__version__\nos.environ['CUDA'] = str(torch.version.cuda)\nprint(torch.__version__)\nprint(torch.version.cuda)\n\n!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0%2Bcu118.html\n!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0%2Bcu118.html\n!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n!pip install torchmetrics\n!pip install networkx Bio","metadata":{"id":"9oq-a6oG1K4P","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc85caf6-e48e-4031-ee0a-9e74da3cfab6","execution":{"iopub.status.busy":"2023-07-25T14:06:51.303622Z","iopub.execute_input":"2023-07-25T14:06:51.303911Z","iopub.status.idle":"2023-07-25T14:08:15.215810Z","shell.execute_reply.started":"2023-07-25T14:06:51.303885Z","shell.execute_reply":"2023-07-25T14:08:15.214480Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2.0.0\n11.8\nLooking in links: https://data.pyg.org/whl/torch-2.0.0%2Bcu118.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.1+pt20cu118\nLooking in links: https://data.pyg.org/whl/torch-2.0.0%2Bcu118.html\nCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse) (1.11.1)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->torch-sparse) (1.23.5)\nInstalling collected packages: torch-sparse\nSuccessfully installed torch-sparse-0.6.17+pt20cu118\nCollecting git+https://github.com/pyg-team/pytorch_geometric.git\n  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-m2133cpx\n  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-m2133cpx\n  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 02cc18d9d6841ecda4eb61eebb48b86f1aaae477\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (4.65.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.23.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (2.31.0)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (3.0.9)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric==2.4.0) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric==2.4.0) (2023.5.7)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric==2.4.0) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric==2.4.0) (3.1.0)\nBuilding wheels for collected packages: torch_geometric\n  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=972129 sha256=21da0bf11ed06a62910e273218aab78210c475bbd9125b606ed659edb26cb4ed\n  Stored in directory: /tmp/pip-ephem-wheel-cache-gp54k6b0/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\nSuccessfully built torch_geometric\nInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.4.0\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.0.0)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.23.5)\nRequirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: lightning-utilities>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.9.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.7.0->torchmetrics) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->torchmetrics) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (3.1)\nCollecting Bio\n  Downloading bio-1.5.9-py3-none-any.whl (276 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: biopython>=1.80 in /opt/conda/lib/python3.10/site-packages (from Bio) (1.81)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from Bio) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from Bio) (4.65.0)\nCollecting mygene (from Bio)\n  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from Bio) (1.5.3)\nRequirement already satisfied: pooch in /opt/conda/lib/python3.10/site-packages (from Bio) (1.6.0)\nCollecting gprofiler-official (from Bio)\n  Downloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from biopython>=1.80->Bio) (1.23.5)\nCollecting biothings-client>=0.2.6 (from mygene->Bio)\n  Downloading biothings_client-0.3.0-py2.py3-none-any.whl (29 kB)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->Bio) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->Bio) (2023.3)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pooch->Bio) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pooch->Bio) (21.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->Bio) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->Bio) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->Bio) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->Bio) (2023.5.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pooch->Bio) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->Bio) (1.16.0)\nInstalling collected packages: gprofiler-official, biothings-client, mygene, Bio\nSuccessfully installed Bio-1.5.9 biothings-client-0.3.0 gprofiler-official-1.0.0 mygene-3.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom scipy.sparse import coo_matrix\nimport multiprocessing as mp\nfrom concurrent.futures import ThreadPoolExecutor\nfrom IPython.display import clear_output\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch_geometric\nfrom torch_geometric.nn import GINConv, global_add_pool, GCNConv, global_max_pool, global_mean_pool, GATConv, SAGEConv\nfrom torch_geometric.data import Data, Batch, DataLoader\nfrom torchmetrics import Accuracy, MultilabelStatScores, MultilabelAccuracy\nfrom torch_geometric.utils import from_networkx, to_networkx, to_dense_batch, convert\nfrom torch.nn import Sequential, Linear, BatchNorm1d, ReLU, SELU\nfrom torch_geometric.nn.models import GAT\nimport torch_geometric.nn.models as models\n\nfrom Bio.SeqUtils.ProtParamData import *\nfrom Bio import SeqIO\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter\nfrom functools import lru_cache\n\n# Required for progressbar widget\nimport progressbar\nfrom datetime import datetime\nimport random\nrandom.seed(datetime.now().timestamp())\n\n# After running each iteration:\ngc.enable()","metadata":{"papermill":{"duration":9.85331,"end_time":"2023-05-09T08:30:19.002985","exception":false,"start_time":"2023-05-09T08:30:09.149675","status":"completed"},"tags":[],"id":"nb0xJgIp1K4R","execution":{"iopub.status.busy":"2023-07-25T14:08:15.218191Z","iopub.execute_input":"2023-07-25T14:08:15.218858Z","iopub.status.idle":"2023-07-25T14:08:24.895967Z","shell.execute_reply.started":"2023-07-25T14:08:15.218818Z","shell.execute_reply":"2023-07-25T14:08:24.895041Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:39: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n/opt/conda/lib/python3.10/site-packages/torch_geometric/typing.py:76: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /opt/conda/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Numpy v\" + np.__version__)\nkaggle_input_data = '/kaggle/input/cafa-5-protein-function-prediction'","metadata":{"papermill":{"duration":0.018272,"end_time":"2023-05-09T08:30:19.030432","exception":false,"start_time":"2023-05-09T08:30:19.01216","status":"completed"},"tags":[],"id":"x6XxiN4L1K4S","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b22d5bd0-a35c-4def-80e2-484c17d35a4b","execution":{"iopub.status.busy":"2023-07-25T14:08:24.897566Z","iopub.execute_input":"2023-07-25T14:08:24.897923Z","iopub.status.idle":"2023-07-25T14:08:24.903421Z","shell.execute_reply.started":"2023-07-25T14:08:24.897887Z","shell.execute_reply":"2023-07-25T14:08:24.902502Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Numpy v1.23.5\n","output_type":"stream"}]},{"cell_type":"code","source":"from os import cpu_count\n# get the number of logical cpu cores\nn_cores = cpu_count()\n# report the number of logical cpu cores\nprint(f'Number of Logical CPU cores: {n_cores}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Dataset","metadata":{"papermill":{"duration":0.008429,"end_time":"2023-05-09T08:30:19.047756","exception":false,"start_time":"2023-05-09T08:30:19.039327","status":"completed"},"tags":[],"id":"WU7qEirr1K4T"}},{"cell_type":"markdown","source":"First we will load the file `train_terms.tsv` which contains the list of annotated terms (functions) for the proteins. We will extract the labels aka `GO term ID` and create a label dataframe for the protein embeddings.","metadata":{"papermill":{"duration":0.008388,"end_time":"2023-05-09T08:30:19.065367","exception":false,"start_time":"2023-05-09T08:30:19.056979","status":"completed"},"tags":[],"id":"Fn7EjFw01K4T"}},{"cell_type":"code","source":"if notebook_run:\n    #train_terms = pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\",sep=\"\\t\")\n    train_terms = pd.read_csv(kaggle_input_data + \"/Train/train_terms.tsv\",sep=\"\\t\")\n    print(train_terms.shape)","metadata":{"papermill":{"duration":3.69155,"end_time":"2023-05-09T08:30:22.766144","exception":false,"start_time":"2023-05-09T08:30:19.074594","status":"completed"},"tags":[],"id":"ggKV4PCs1K4T","colab":{"base_uri":"https://localhost:8080/"},"outputId":"25f031ff-bab8-4cc5-ca0d-21e8d38de8cd","execution":{"iopub.status.busy":"2023-07-25T14:08:24.906575Z","iopub.execute_input":"2023-07-25T14:08:24.907363Z","iopub.status.idle":"2023-07-25T14:08:24.913975Z","shell.execute_reply.started":"2023-07-25T14:08:24.907331Z","shell.execute_reply":"2023-07-25T14:08:24.913069Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"`train_terms` dataframe is composed of 3 columns and 5363863 entries. We can see all 3 dimensions of our dataset by printing out the first 5 entries using the following code:","metadata":{"papermill":{"duration":0.008358,"end_time":"2023-05-09T08:30:22.783293","exception":false,"start_time":"2023-05-09T08:30:22.774935","status":"completed"},"tags":[],"id":"Vr98Z1qX1K4T"}},{"cell_type":"code","source":"if notebook_run:\n    train_terms = train_terms.sample(150000)","metadata":{"papermill":{"duration":0.038607,"end_time":"2023-05-09T08:30:22.830633","exception":false,"start_time":"2023-05-09T08:30:22.792026","status":"completed"},"tags":[],"id":"Cvb-XyY91K4U","execution":{"iopub.status.busy":"2023-07-25T14:08:24.915102Z","iopub.execute_input":"2023-07-25T14:08:24.915952Z","iopub.status.idle":"2023-07-25T14:08:24.928449Z","shell.execute_reply.started":"2023-07-25T14:08:24.915915Z","shell.execute_reply":"2023-07-25T14:08:24.927453Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if notebook_run:\n    train_terms.loc[train_terms['EntryID'] == 'Q59VP0']","metadata":{"scrolled":true,"id":"brMGEGHw1K4U","colab":{"base_uri":"https://localhost:8080/","height":49},"outputId":"4832995c-95d7-4f41-f391-2935aaf1ee76","execution":{"iopub.status.busy":"2023-07-25T14:08:24.931475Z","iopub.execute_input":"2023-07-25T14:08:24.931751Z","iopub.status.idle":"2023-07-25T14:08:24.939080Z","shell.execute_reply.started":"2023-07-25T14:08:24.931717Z","shell.execute_reply":"2023-07-25T14:08:24.938149Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"If we look at the first entry of `train_terms.tsv`, we can see that it contains protein id(`A0A009IHW8`), the GO term(`GO:0008152`) and its aspect(`BPO`).","metadata":{"papermill":{"duration":0.008764,"end_time":"2023-05-09T08:30:22.848867","exception":false,"start_time":"2023-05-09T08:30:22.840103","status":"completed"},"tags":[],"id":"HsxDFooS1K4U"}},{"cell_type":"markdown","source":"# A different kind of embedding\n\nWe introduce a new embedding for Proteins based on the notion of Recurrence Networks: Olyaee, M. H., Yaghoubi, A., & Yaghoobi, M. (2016). Predicting protein structural classes based on complex networks and recurrence analysis. Journal of theoretical biology, 404, 375–382. https://doi.org/10.1016/j.jtbi.2016.06.018\n\nInstead of using the provided embeddings, we will train Graph Neural Networks on a new embedding for each graph, defined by recurrence networks.\n\n**Let's start by defining a function that takes a Protein Sequence String and creates a recurrence network:**","metadata":{"id":"MbqodfXE1K4W"}},{"cell_type":"code","source":"def protein_recurrence_network(sequence):\n    # Create an empty graph for the recurrence network\n    graph = nx.DiGraph()\n\n    # Use a Counter to store the edge weights and add nodes and edges to the graph\n    graph.add_weighted_edges_from(((char1, char2, weight / len(sequence)) \n                for (char1, char2), weight in Counter(zip(sequence, sequence[1:])).items()))\n    \n    return protein_attributes(graph)\n\n@lru_cache(maxsize=32)  # Use None for unbounded cache size\ndef protein_attributes(graph):\n    nx.set_node_attributes(graph, nx.betweenness_centrality(graph), \"betweenness\")\n\n    # Set node attributes\n    attributes = {\n        node: {\n            k: v.get(node, 0.) for k, v in gravy_scales.items()\n        } | {\n            'flexibility': Flex.get(node, 0.),\n            'hydrophilicity': hw.get(node, 0.),\n            'surface_accessibility': em.get(node, 0.),\n            'janin_interior': ja.get(node, 0.)\n        }\n        for node in graph.nodes\n    }\n\n    # Update attributes for all nodes in a single step\n    nx.set_node_attributes(graph, attributes)\n\n    # Set interaction details using list comprehension (preserving existing weights)\n    graph.add_edges_from([\n        (v1, v2, {'instability_index': DIWV.get(v1, {}).get(v2, 0.)})\n        for v1, v2 in graph.edges\n    ])\n\n    return graph","metadata":{"id":"FI3rmj3H1K4X","execution":{"iopub.status.busy":"2023-07-25T14:08:24.940677Z","iopub.execute_input":"2023-07-25T14:08:24.941209Z","iopub.status.idle":"2023-07-25T14:08:24.955788Z","shell.execute_reply.started":"2023-07-25T14:08:24.941177Z","shell.execute_reply":"2023-07-25T14:08:24.954758Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Define a function to process a record and return the protein recurrence network\n#def process_record(record):\n#    return record.id, protein_recurrence_network(str(record.seq))\n@lru_cache(maxsize=32)  # Use None for unbounded cache size\ndef process_record(record):\n    if record.id in train_terms_set:\n        return record.id, protein_recurrence_network(str(record.seq))\n    else:\n        return None\n\nif notebook_run:\n    train_terms_set = set(train_terms['EntryID'].values)\n    \n    # Parse the fasta file\n    records = SeqIO.parse(kaggle_input_data + \"/Train/train_sequences.fasta\", \"fasta\")\n\n    # Use map to process the records in parallel\n    protein_rn_dict = dict(map(process_record, (record for record in records if record.id in train_terms['EntryID'].values)))\n    g_train_protein_ids = np.array(list(protein_rn_dict.keys()))","metadata":{"id":"VD5T4vMS1K4X","execution":{"iopub.status.busy":"2023-07-25T14:08:24.957135Z","iopub.execute_input":"2023-07-25T14:08:24.957619Z","iopub.status.idle":"2023-07-25T14:08:24.966097Z","shell.execute_reply.started":"2023-07-25T14:08:24.957585Z","shell.execute_reply":"2023-07-25T14:08:24.965038Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Let's draw one of these graphs to see what it looks like.","metadata":{"id":"bD5sC7v01K4X"}},{"cell_type":"code","source":"if notebook_run:\n    G_id = train_terms['EntryID'].sample(1).values[0]\n    G = protein_rn_dict[G_id]\n    fig = plt.figure(figsize=(12,12))\n    # Extract edge weights\n    edge_weights = nx.get_edge_attributes(G, 'weight')\n    # Round the edge weights to 4 decimal places\n    edge_weights = {k: round(v, 4) for k, v in edge_weights.items()}\n\n    # Draw the graph\n    pos = nx.spring_layout(G)\n    nx.draw_networkx(G, pos, with_labels=True, node_color='lightblue')\n\n    # Draw edge labels\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_weights, font_color='red', font_size=8)\n    plt.title(G_id)\n\n    # Show the graph\n    plt.axis('off')\n    plt.show()","metadata":{"id":"BxPwR0if1K4X","colab":{"base_uri":"https://localhost:8080/","height":961},"outputId":"ae50251b-462b-4d18-f046-0816358ea0ca","execution":{"iopub.status.busy":"2023-07-25T14:08:24.967636Z","iopub.execute_input":"2023-07-25T14:08:24.968044Z","iopub.status.idle":"2023-07-25T14:08:24.980003Z","shell.execute_reply.started":"2023-07-25T14:08:24.967996Z","shell.execute_reply":"2023-07-25T14:08:24.979037Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"if notebook_run:\n    list(G.nodes(data=True))\n    #for v1,v2 in G.edges:\n    #  print(v1)\n    #  print(v2)","metadata":{"id":"Km07L70J4YFG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"014b1315-56af-4392-833b-7880a77cb349","scrolled":true,"execution":{"iopub.status.busy":"2023-07-25T14:08:24.986702Z","iopub.execute_input":"2023-07-25T14:08:24.986972Z","iopub.status.idle":"2023-07-25T14:08:24.993083Z","shell.execute_reply.started":"2023-07-25T14:08:24.986944Z","shell.execute_reply":"2023-07-25T14:08:24.991913Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"if notebook_run:\n    # Just looking for weird proteins\n    for k in protein_rn_dict:\n        if 'U' in protein_rn_dict[k].nodes():\n            print(k)\n            print(protein_rn_dict[k].nodes())\n            print(protein_rn_dict[k])","metadata":{"scrolled":true,"id":"f4XokvA01K4X","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f36baad6-6ce8-4669-ab92-263eb903cec6","execution":{"iopub.status.busy":"2023-07-25T14:08:24.994671Z","iopub.execute_input":"2023-07-25T14:08:24.995046Z","iopub.status.idle":"2023-07-25T14:08:25.002963Z","shell.execute_reply.started":"2023-07-25T14:08:24.994994Z","shell.execute_reply":"2023-07-25T14:08:25.002027Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the dataset\n\nReference: https://www.kaggle.com/code/alexandervc/baseline-multilabel-to-multitarget-binary","metadata":{"papermill":{"duration":0.009208,"end_time":"2023-05-09T08:30:32.825978","exception":false,"start_time":"2023-05-09T08:30:32.81677","status":"completed"},"tags":[],"id":"EJ6434191K4X"}},{"cell_type":"markdown","source":"First we will extract all the needed labels(`GO term ID`) from `train_terms.tsv` file. There are more than 40,000 labels. In order to simplify our model, we will choose the most frequent 1500 `GO term ID`s as labels.","metadata":{"papermill":{"duration":0.009674,"end_time":"2023-05-09T08:30:32.845065","exception":false,"start_time":"2023-05-09T08:30:32.835391","status":"completed"},"tags":[],"id":"6LjXf3Bp1K4X"}},{"cell_type":"markdown","source":"Let's plot the most frequent 100 `GO Term ID`s in `train_terms.tsv`.","metadata":{"papermill":{"duration":0.009238,"end_time":"2023-05-09T08:30:32.863785","exception":false,"start_time":"2023-05-09T08:30:32.854547","status":"completed"},"tags":[],"id":"PasOnoXy1K4Y"}},{"cell_type":"code","source":"if notebook_run:\n    # Select first 1500 values for plotting\n    plot_df = train_terms['term'].value_counts().iloc[:100]\n\n    figure, axis = plt.subplots(1, 1, figsize=(12, 6))\n\n    bp = sns.barplot(ax=axis, x=np.array(plot_df.index), y=plot_df.values)\n    bp.set_xticklabels(bp.get_xticklabels(), rotation=90, size = 6)\n    axis.set_title('Top 100 frequent GO term IDs')\n    bp.set_xlabel(\"GO term IDs\", fontsize = 12)\n    bp.set_ylabel(\"Count\", fontsize = 12)\n    plt.show()","metadata":{"papermill":{"duration":1.592489,"end_time":"2023-05-09T08:30:34.465912","exception":false,"start_time":"2023-05-09T08:30:32.873423","status":"completed"},"tags":[],"id":"23FUlWzw1K4Y","colab":{"base_uri":"https://localhost:8080/","height":607},"outputId":"6fb28ae9-631c-4286-b831-7987248df807","execution":{"iopub.status.busy":"2023-07-25T14:08:25.004742Z","iopub.execute_input":"2023-07-25T14:08:25.005094Z","iopub.status.idle":"2023-07-25T14:08:25.015257Z","shell.execute_reply.started":"2023-07-25T14:08:25.005064Z","shell.execute_reply":"2023-07-25T14:08:25.014243Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"We will now save the first 1500 most frequent GO term Ids into a list.","metadata":{"papermill":{"duration":0.010458,"end_time":"2023-05-09T08:30:34.487707","exception":false,"start_time":"2023-05-09T08:30:34.477249","status":"completed"},"tags":[],"id":"UbjLGFEK1K4Y"}},{"cell_type":"code","source":"if notebook_run:\n    # Set the limit for label\n    num_of_labels = 1500\n\n    # Take value counts in descending order and fetch first 1500 `GO term ID` as labels\n    labels = train_terms['term'].value_counts().index[:num_of_labels].tolist()","metadata":{"papermill":{"duration":0.523976,"end_time":"2023-05-09T08:30:35.021974","exception":false,"start_time":"2023-05-09T08:30:34.497998","status":"completed"},"tags":[],"id":"PePJVY871K4Y","execution":{"iopub.status.busy":"2023-07-25T14:08:25.016802Z","iopub.execute_input":"2023-07-25T14:08:25.017197Z","iopub.status.idle":"2023-07-25T14:08:25.030431Z","shell.execute_reply.started":"2023-07-25T14:08:25.017165Z","shell.execute_reply":"2023-07-25T14:08:25.029515Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Next, we will create a new dataframe by filtering the train terms with the selected `GO Term ID`s.","metadata":{"papermill":{"duration":0.009833,"end_time":"2023-05-09T08:30:35.042088","exception":false,"start_time":"2023-05-09T08:30:35.032255","status":"completed"},"tags":[],"id":"rfoR7jaK1K4f"}},{"cell_type":"code","source":"if notebook_run:\n    # Fetch the train_terms data for the relevant labels only\n    train_terms_updated = train_terms.loc[train_terms['term'].isin(labels)]","metadata":{"papermill":{"duration":0.668657,"end_time":"2023-05-09T08:30:35.720953","exception":false,"start_time":"2023-05-09T08:30:35.052296","status":"completed"},"tags":[],"id":"QmbKQ-wX1K4g","execution":{"iopub.status.busy":"2023-07-25T14:08:25.032672Z","iopub.execute_input":"2023-07-25T14:08:25.033349Z","iopub.status.idle":"2023-07-25T14:08:25.041150Z","shell.execute_reply.started":"2023-07-25T14:08:25.033317Z","shell.execute_reply":"2023-07-25T14:08:25.040074Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Let us plot the aspect values in the new **train_terms_updated** dataframe using a pie chart.","metadata":{"papermill":{"duration":0.009797,"end_time":"2023-05-09T08:30:35.741328","exception":false,"start_time":"2023-05-09T08:30:35.731531","status":"completed"},"tags":[],"id":"hs4Ndc0k1K4g"}},{"cell_type":"code","source":"if notebook_run:\n    pie_df = train_terms_updated['aspect'].value_counts()\n    palette_color = sns.color_palette('bright')\n    plt.pie(pie_df.values, labels=np.array(pie_df.index), colors=palette_color, autopct='%.0f%%')\n    plt.show()","metadata":{"papermill":{"duration":0.419624,"end_time":"2023-05-09T08:30:36.171193","exception":false,"start_time":"2023-05-09T08:30:35.751569","status":"completed"},"tags":[],"id":"F3UvKHwt1K4g","colab":{"base_uri":"https://localhost:8080/","height":406},"outputId":"702cad97-8748-4bd7-efa5-74bc3f17486c","execution":{"iopub.status.busy":"2023-07-25T14:08:25.042645Z","iopub.execute_input":"2023-07-25T14:08:25.043006Z","iopub.status.idle":"2023-07-25T14:08:25.052539Z","shell.execute_reply.started":"2023-07-25T14:08:25.042975Z","shell.execute_reply":"2023-07-25T14:08:25.051667Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"As you can see, majority of the `GO term Id`s have BPO(Biological Process Ontology) as their aspect.","metadata":{"papermill":{"duration":0.016642,"end_time":"2023-05-09T08:30:36.204943","exception":false,"start_time":"2023-05-09T08:30:36.188301","status":"completed"},"tags":[],"id":"AKV3JhgU1K4h"}},{"cell_type":"markdown","source":"Since this is a multi label classification problem, in the labels array we will denote the presence or absence of each Go Term Id for a protein id using a 1 or 0.\nFirst, we will create a numpy array `train_labels` of required size for the labels. To update the `train_labels` array with the appropriate values, we will loop through the label list.","metadata":{"id":"0sexUW1v1K4i"}},{"cell_type":"code","source":"if notebook_run:\n    # Setup progressbar settings.\n    # This is strictly for aesthetic.\n    bar = progressbar.ProgressBar(maxval=num_of_labels, \\\n        widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n\n    # Create an empty dataframe of required size for storing the labels,\n    # i.e, train_size x num_of_labels (142246 x 1500)\n    train_size = g_train_protein_ids.shape[0] # len(X)\n    train_labels = np.zeros((train_size, num_of_labels))\n\n    # Convert from numpy to pandas series for better handling\n    series_train_protein_ids = pd.Series(g_train_protein_ids)\n\n    # Generate a dict where key is label and value is the corresponding proteins\n    @lru_cache(maxsize=32)  # Use None for unbounded cache size\n    def get_label_proteins(label):\n        proteins = train_terms_updated[train_terms_updated['term'] == label]['EntryID'].unique()\n        return label, proteins\n\n    label_protein_dict = dict(map(get_label_proteins, labels))\n\n    # Loop through each label\n    for i, label in enumerate(labels):\n        # Fetch all the unique EntryId aka proteins related to the current label(GO term ID)\n        label_related_proteins = label_protein_dict[label]\n\n        # In the series_train_protein_ids pandas series, if a protein is related\n        # to the current label, then mark it as 1, else 0.\n        # Replace the ith column of train_labels with that pandas series.\n        train_labels[:,i] =  series_train_protein_ids.isin(label_related_proteins).astype(float)\n\n        # Progress bar percentage increase\n        bar.update(i+1)\n\n    # Notify the end of progress bar\n    bar.finish()\n\n    # Convert train_labels numpy into pandas dataframe\n    labels_df = pd.DataFrame(data = train_labels, columns = labels)\n    print(labels_df.shape)\n","metadata":{"id":"qM8RdXsyDoDQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"27e9aff0-3c75-4976-8c59-221ef156dbaf","execution":{"iopub.status.busy":"2023-07-25T14:08:25.053955Z","iopub.execute_input":"2023-07-25T14:08:25.054882Z","iopub.status.idle":"2023-07-25T14:08:25.064840Z","shell.execute_reply.started":"2023-07-25T14:08:25.054849Z","shell.execute_reply":"2023-07-25T14:08:25.064052Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"The final labels dataframe (`label_df`) is composed of 1500 columns and 142246 entries (though we brought it down to 10000). We can see all 1500 dimensions(results will be truncated since the number of columns is big) of our dataset by printing out the first 5 entries using the following code:","metadata":{"papermill":{"duration":0.010097,"end_time":"2023-05-09T08:38:51.971947","exception":false,"start_time":"2023-05-09T08:38:51.96185","status":"completed"},"tags":[],"id":"nrQKV4Cn1K4j"}},{"cell_type":"code","source":"if notebook_run:\n    labels_df.head()","metadata":{"papermill":{"duration":0.048128,"end_time":"2023-05-09T08:38:52.031041","exception":false,"start_time":"2023-05-09T08:38:51.982913","status":"completed"},"tags":[],"id":"KZeiIuqY1K4k","colab":{"base_uri":"https://localhost:8080/","height":299},"outputId":"515c6879-e3d7-4a6b-cef6-68f20eeae8e0","execution":{"iopub.status.busy":"2023-07-25T14:08:25.066257Z","iopub.execute_input":"2023-07-25T14:08:25.066619Z","iopub.status.idle":"2023-07-25T14:08:25.078422Z","shell.execute_reply.started":"2023-07-25T14:08:25.066586Z","shell.execute_reply":"2023-07-25T14:08:25.077757Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"if notebook_run:\n    num_of_labels","metadata":{"id":"bIl4xgNi1K4k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"98c17290-242a-4782-e829-f33f7475870e","execution":{"iopub.status.busy":"2023-07-25T14:08:25.079438Z","iopub.execute_input":"2023-07-25T14:08:25.080169Z","iopub.status.idle":"2023-07-25T14:08:25.089656Z","shell.execute_reply.started":"2023-07-25T14:08:25.080137Z","shell.execute_reply":"2023-07-25T14:08:25.088490Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Graph Preparation\n\nNext, we'll define our GNN model class, which will inherit from nn.Module:","metadata":{"id":"oIKSnaYQ1K4l"}},{"cell_type":"code","source":"class GraphSAGE(torch.nn.Module):\n    def __init__(self, in_channels=1, hidden_dim = 128, out_channels=1500):\n        \"\"\"\n        Represents a 3-layer GraphSAGE GNN model\n        with embedding and hidden dimension of hidden_dim.\n        \"\"\"\n        super(GraphSAGE, self).__init__()\n        self.tag = 'GraphSAGE'\n        self.pre_embs = nn.Embedding(in_channels, hidden_dim)\n\n        self.convs = nn.ModuleList()\n        self.selus = nn.ModuleList()\n        self.dropouts = nn.ModuleList()\n        self.layer_norms = nn.ModuleList()\n\n        # Input layer\n        self.convs.append(SAGEConv(in_channels, hidden_dim))\n        self.selus.append(nn.SELU())\n        self.dropouts.append(nn.Dropout(0.1))\n        self.layer_norms.append(nn.LayerNorm(hidden_dim))\n\n        # Hidden layers\n        for _ in range(3):\n            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n            self.selus.append(SELU())\n            self.dropouts.append(nn.Dropout(0.1))\n            self.layer_norms.append(nn.LayerNorm(hidden_dim))\n\n        # Output layer\n        self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(3*hidden_dim, out_channels)\n        self.out.weight.data.fill_(1.)\n            \n    def forward(self, data):\n        \"\"\"\n        Runs a forward pass through GraphSAGE with given initial skill IDs and\n        edge_index and edge_weights.\n\n        Arguments:\n          - data: Input data containing node features, edge indices, and edge attributes.\n\n        Returns:\n          - logits: Output logits from the final node embedding for classification.\n        \"\"\"\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        # Convert x tensor to Long type\n        for conv, selu, dropout, layer_norm in zip(self.convs, self.selus, self.dropouts, self.layer_norms):\n            x = layer_norm(dropout(selu(conv(x, edge_index))))\n\n        x_add = global_add_pool(x, batch)\n        x_mean = global_mean_pool(x, batch)\n        x_max = global_max_pool(x, batch)\n        x = torch.cat([x_add, x_mean, x_max], dim=-1)\n        return self.out(x)\n\nclass GraphGAT(nn.Module):\n    def __init__(self, in_channels, hidden_dim, num_layers, out_channels, dropout, act):\n        super(GraphGAT, self).__init__()\n        self.tag = 'GraphGAT'\n        self.pre_embs = nn.Embedding(in_channels, hidden_dim)\n\n        self.convs = nn.ModuleList()\n        self.selus = nn.ModuleList()\n        self.dropouts = nn.ModuleList()\n\n        # Input layer\n        self.convs.append(GATConv(in_channels, hidden_dim))\n        self.selus.append(nn.SELU())\n        self.dropouts.append(nn.Dropout(dropout))\n        \n        # Hidden layers\n        for _ in range(num_layers):\n            self.convs.append(GATConv(hidden_dim, hidden_dim))\n            self.selus.append(SELU())\n            self.dropouts.append(nn.Dropout(dropout))\n\n        # Output layer\n        self.convs.append(GATConv(hidden_dim, hidden_dim, concat=False, dropout=0.6))\n        self.dropout = nn.Dropout(dropout)\n        self.out = nn.Linear(3*hidden_dim, out_channels)\n\n    def forward(self, data):\n        \"\"\"\n        Runs a forward pass through the GraphGAT model with given initial node features,\n        edge indices, and edge attributes (edge weights).\n\n        Arguments:\n          - data: Input data containing node features, edge indices, and edge attributes.\n\n        Returns:\n          - logits: Output logits from the final node embedding for classification.\n          - probabilities: Probabilities obtained from applying the sigmoid function to the logits.\n\n        \"\"\"\n        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n        # Dropout before the GAT layer is used to avoid overfitting\n        x = self.dropouts[0](x)\n\n        # Convert x tensor to Long type\n        for conv, selu, dropout in zip(self.convs, self.selus, self.dropouts[1:]):\n            x = dropout(selu(conv(x, edge_index, edge_attr)))\n\n        x_pooled = torch.cat([\n            global_add_pool(x, batch),\n            global_mean_pool(x, batch),\n            global_max_pool(x, batch),\n        ], dim=-1)\n        \n        return self.out(x_pooled), F.sigmoid(self.out(x_pooled))\n","metadata":{"scrolled":true,"id":"5lrHQvSH1K4l","execution":{"iopub.status.busy":"2023-07-25T14:08:25.092365Z","iopub.execute_input":"2023-07-25T14:08:25.092712Z","iopub.status.idle":"2023-07-25T14:08:25.114037Z","shell.execute_reply.started":"2023-07-25T14:08:25.092682Z","shell.execute_reply":"2023-07-25T14:08:25.113065Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Here, **hidden_dim** is the dimensionality of hidden layers, and **output_dim** is the number of output classes (1500 in this case).\n\nNow, let's define a function to convert each NetworkX graph into a PyTorch Geometric **Data** object:","metadata":{"id":"BwaU1rn01K4n"}},{"cell_type":"code","source":"# Assuming nx_graphs_train and nx_graphs_test are your lists of NetworkX graphs\n# and labels_train and labels_test are your lists of labels for train and test datasets respectively\ndef from_networkx_to_data(nx_graph, labels):\n    data = from_networkx(nx_graph, group_node_attrs=all, group_edge_attrs=all)\n\n    # Add labels to the data\n    data.y = torch.tensor(labels, dtype=torch.float).unsqueeze(0)\n    return data\n    \ndef from_networkx_to_data_list(nx_graphs, labels):\n    return list(map(from_networkx_to_data, nx_graphs,labels))","metadata":{"id":"qTOl5aMC1K4n","execution":{"iopub.status.busy":"2023-07-25T14:08:25.115334Z","iopub.execute_input":"2023-07-25T14:08:25.115880Z","iopub.status.idle":"2023-07-25T14:08:25.128316Z","shell.execute_reply.started":"2023-07-25T14:08:25.115848Z","shell.execute_reply":"2023-07-25T14:08:25.127439Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"In this function, we convert the adjacency matrix of the graph into the edge index format expected by PyTorch Geometric. We also convert the labels into a torch tensor.\n\n# Training\n\nNow, let's define the training loop and train the GNN model on your labeled graphs:","metadata":{"id":"FpwTzGAl1K4o"}},{"cell_type":"code","source":"if notebook_run:\n    # Assuming you have a list of NetworkX graphs and corresponding labels\n\n    #protein_ids = list(protein_rn_dict.keys())\n    protein_ids = g_train_protein_ids\n    num_features = 33\n    num_classes = 1500\n    graphs, graphs_test, labels, labels_test = train_test_split([protein_rn_dict[k] for k in protein_ids],\n                                                                labels_df.iloc[np.where(np.isin(g_train_protein_ids, protein_ids))].values,\n                                                                test_size=0.2, random_state=int(datetime.now().timestamp()))\n\n    # Convert each graph to a PyTorch Geometric Data object and place in data loader\n    train_loader = DataLoader(from_networkx_to_data_list(graphs, labels), batch_size=256, shuffle=True)\n    test_loader = DataLoader(from_networkx_to_data_list(graphs_test, labels_test), batch_size=256, shuffle=False)","metadata":{"id":"VBPSIOJm1K4o","colab":{"base_uri":"https://localhost:8080/"},"outputId":"134e042a-31b8-4537-8157-7a576463b3ef","execution":{"iopub.status.busy":"2023-07-25T14:08:25.129670Z","iopub.execute_input":"2023-07-25T14:08:25.130358Z","iopub.status.idle":"2023-07-25T14:08:25.139465Z","shell.execute_reply.started":"2023-07-25T14:08:25.130325Z","shell.execute_reply":"2023-07-25T14:08:25.138603Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"We'll introduce a method to do all of this data preparation at once, such that we don't store all of these intermediate variables in memory.","metadata":{}},{"cell_type":"code","source":"class ProteinDataset(Dataset):\n    def __init__(self, protein_sequences, labels=torch.zeros((1500,1)), training=False):\n        self.training = training\n        if training:\n            # Use ThreadPoolExecutor to parallelize the process\n            with concurrent.futures.ThreadPoolExecutor(labels.shape[0]) as executor:\n                self.dataset = list(executor.map(self.process_data, protein_sequences, labels))\n        else:            \n            self.protein_sequences = protein_sequences\n            self.labels = labels\n\n    # Function to process protein_recurrence_network and from_networkx_to_data in parallel\n    def process_data(self, protein_sequence, label):\n        return from_networkx_to_data(protein_recurrence_network(protein_sequence), label)\n\n    def __len__(self):\n        if self.training:\n            return len(self.dataset)\n        else:\n            return len(self.protein_sequences)\n\n    def __getitem__(self, idx):\n        if self.training:\n            return self.dataset[idx]\n        else:\n            # Convert the NetworkX graph to a PyTorch Geometric Data object\n            return self.process_data(self.protein_sequences[idx], self.labels[idx])\n\ndef calculate_class_weights(labels_df):\n    \"\"\"\n    Calculate class weights based on the number of occurrences for each class in the labels DataFrame.\n\n    Args:\n        labels_df (pd.DataFrame): DataFrame containing class labels as columns and 1s/0s indicating class membership.\n\n    Returns:\n        weight_tensor (torch.Tensor): A tensor containing class weights for each class.\n    \"\"\"\n    class_frequencies = labels_df.sum(axis=0)\n    total_samples = len(labels_df)\n    class_weights = total_samples / (class_frequencies * len(labels_df.columns))\n    weight_tensor = torch.tensor([class_weights[i] for i in range(len(class_weights))], dtype=torch.float)\n    return weight_tensor\n\ndef prepare_training_data_and_models(sample_data_size=150000, num_of_labels=1500, training=True, just_data=False, verbose=True):\n    \"\"\"\n    Prepare the training data and models for GraphGAT.\n\n    Args:\n        sample_data_size (int): Number of samples to use in the training set.\n        num_of_labels (int): Limit of how many labels (most frequently occurring) to include.\n        training (bool): True if preparing for training, False otherwise.\n        just_data (bool): True to return only data loaders, False to return model and other components as well.\n        verbose (bool): True to print verbose information during data preparation.\n\n    Returns:\n        Depending on the `just_data` flag, returns different values:\n        - If just_data is True, returns train_loader and test_loader (data loaders).\n        - If just_data is False, returns train_loader, test_loader, model, device, class_names, class_weights.\n    \"\"\"\n    train_terms = pd.read_csv(kaggle_input_data + \"/Train/train_terms.tsv\",sep=\"\\t\")\n    if verbose:\n        print(\"Training terms shape: \")\n        print(train_terms.shape)\n\n    if sample_data_size:\n        train_terms = train_terms.sample(sample_data_size)\n\n    if verbose:\n        print(\"Getting record IDs\")\n\n    # Parse the fasta file\n    entry_id_set = set(train_terms['EntryID'].values)\n    record_dict = SeqIO.index(kaggle_input_data + \"/Train/train_sequences.fasta\", \"fasta\")\n    train_protein_ids = np.array(list(set(record_dict.keys()).intersection(entry_id_set)))\n    \n    if verbose:\n        print(str(len(train_protein_ids)) + \" Protein IDs found\")\n\n    if verbose:\n        print(\"Fetching Label Values\")\n    \n    # Take value counts in descending order and fetch first 1500 `GO term ID` as labels\n    labels = train_terms['term'].value_counts().index[:num_of_labels].tolist()\n    \n    # Fetch the train_terms data for the relevant labels only\n    train_terms_updated = train_terms.loc[train_terms['term'].isin(labels)]\n    \n    if verbose:\n        print(\"Establishing labels\")\n    \n    # Create an empty dataframe of required size for storing the labels,\n    # i.e, train_size x num_of_labels (142246 x 1500)\n    train_size = train_protein_ids.shape[0]\n    train_labels = np.zeros((train_size, num_of_labels))\n\n    # Convert from numpy to pandas series for better handling\n    series_train_protein_ids = pd.Series(train_protein_ids)\n\n    # Generate a dict where key is label and value is the corresponding proteins\n    @lru_cache(maxsize=32)  # Use None for unbounded cache size\n    def get_label_proteins(label):\n        return label, train_terms_updated[train_terms_updated['term'] == label]['EntryID'].unique()\n\n    def get_label_proteins_parallel(labels):\n        # Use ThreadPoolExecutor to parallelize the process\n        with ThreadPoolExecutor(len(labels)) as executor:\n            try:\n                return dict(executor.map(get_label_proteins, labels))\n            except Exception as exc:\n                print(f\"Error processing label {label}: {exc}\")\n    \n    # Each label (GO Term ID) is now mapped to proteins\n    if verbose:\n        print(\"Creating Label-Protein Dictionary\")\n    \n    # Merge train_terms_updated with labels DataFrame on 'term' column to efficiently filter data for each label\n    label_protein_dict = {}\n    labels_df = pd.DataFrame({'term': labels})  # Create a DataFrame with labels for merging\n    merged_data = train_terms_updated.merge(labels_df, on='term', how='right')\n\n    # Group the merged data by 'term' and extract unique proteins for each label\n    grouped_terms = merged_data.groupby('term')\n    label_protein_dict = {label: group['EntryID'].unique() for label, group in grouped_terms}\n\n    if verbose:\n        print(\"Processing Label-Protein Dictionary\")\n\n    # Function to process each label in parallel\n    def process_label(label_args):\n        i, label = label_args\n        # 1. Fetch all the unique EntryId aka proteins related to the current label(GO term ID)\n        # 2. Use vectorized operations to mark 1 for related proteins, 0 for others\n        train_labels[:, i] = series_train_protein_ids.isin(label_protein_dict[label]).astype(float)\n\n    # Use ThreadPoolExecutor to parallelize the label processing\n    with concurrent.futures.ThreadPoolExecutor(len(labels)) as executor:\n        for _ in progressbar.progressbar(executor.map(process_label, enumerate(labels)), max_value=len(labels)):\n            pass\n\n    # Convert train_labels numpy into pandas dataframe\n    labels_df = pd.DataFrame(data = train_labels, columns = labels)\n    num_features = 33\n    num_classes = num_of_labels\n    proteins_train, proteins_test, labels, labels_test = train_test_split(train_protein_ids,\n                                                                          labels_df.values,\n                                                                          test_size=0.2,\n                                                                          random_state=int(datetime.now().timestamp()))    \n    if verbose:\n        print(\"Getting sequences for training\")\n    record_dict = SeqIO.index(kaggle_input_data + \"/Train/train_sequences.fasta\", \"fasta\")\n    training_dataset = ProteinDataset((str(record_dict[id].seq) for id in proteins_train), labels, training=training)\n    \n    if verbose:\n        print(\"Getting sequences for testing\")\n    record_dict = SeqIO.index(kaggle_input_data + \"/Train/train_sequences.fasta\", \"fasta\")\n    test_dataset = ProteinDataset((str(record_dict[id].seq) for id in proteins_test), labels_test, training=training)\n\n    if verbose:\n        print(\"Computing class weights\")\n\n    class_weights = calculate_class_weights(labels_df)\n\n    if verbose:\n        print(\"Creating sampler based on class weights\")\n    # Convert the labels to a list of class names\n    # Assuming labels are in a DataFrame where each row contains 1s and 0s for each class\n    class_names = labels_df.columns.tolist()\n\n    # Use LabelEncoder to convert class names to integer indices\n    #label_encoder = LabelEncoder()\n    #label_encoder.fit(class_names)\n    #class_indices = labels_df.apply(lambda x: label_encoder.transform(x.index[x == 1]), axis=1)\n    # Convert the labels DataFrame to a numpy array\n    labels_array = labels_df.values\n\n    # Use numpy to calculate the class indices directly\n    class_indices = np.dot(labels_array, 2 ** np.arange(labels_array.shape[1])[::-1])\n\n    # Create a WeightedRandomSampler using the computed class_weights\n    sampler = torch.utils.data.WeightedRandomSampler(weights=class_weights, num_samples=len(class_indices), replacement=True)\n\n    if verbose:\n        print(\"Putting training data into Data Loader\")\n    # Convert each graph to a PyTorch Geometric Data object and place in data loader\n    train_loader = DataLoader(training_dataset, batch_size=2048, num_workers=4, sampler=sampler)#, pin_memory=True)\n    if verbose:\n        print(\"Putting test data into Data Loader\")\n    test_loader = DataLoader(test_dataset, batch_size=2048, num_workers=4, sampler=sampler)#, pin_memory=True)\n    \n    # Prepare Model\n    if verbose:\n        print(\"Preparing model\")\n    def weights_init(m):\n        if isinstance(m, nn.Linear):\n            torch.nn.init.xavier_uniform_(m.weight)\n            m.bias.data.fill_(1)\n\n    if just_data:\n        return train_loader, test_loader\n    else:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        model = GraphGAT(in_channels=num_features,hidden_dim=128,num_layers=3,out_channels=num_classes,dropout=0.05,act='selu').to(device)\n        #model = GraphSAGE(num_features, 128, num_classes).to(device)\n        # Initialize final layer to 1s\n        model.apply(weights_init)\n        hidden_channels = 64\n        num_layers = 30\n        return train_loader, test_loader, model, device, labels_df.columns, class_weights\n    \n# Use threshold to define predicted labels and invoke sklearn's metrics with different averaging strategies.\ndef calculate_metrics(pred, target, threshold=0.5):\n    pred = np.array(pred > threshold, dtype=float)\n    return {'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),\n            'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),\n            'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),\n            'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),\n            'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),\n            'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),\n            'samples/precision': precision_score(y_true=target, y_pred=pred, average='samples'),\n            'samples/recall': recall_score(y_true=target, y_pred=pred, average='samples'),\n            'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples'),\n            }","metadata":{"execution":{"iopub.status.busy":"2023-07-25T14:08:25.140937Z","iopub.execute_input":"2023-07-25T14:08:25.141560Z","iopub.status.idle":"2023-07-25T14:08:25.185817Z","shell.execute_reply.started":"2023-07-25T14:08:25.141528Z","shell.execute_reply":"2023-07-25T14:08:25.184727Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"if not notebook_run:    \n    start = time.time()\n    train_loader, test_loader, model, device, out_labels, class_weights = prepare_training_data_and_models(sample_data_size=None)\n    end = time.time()\n    print(end - start)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T14:08:25.187306Z","iopub.execute_input":"2023-07-25T14:08:25.187619Z","iopub.status.idle":"2023-07-25T14:11:59.634175Z","shell.execute_reply.started":"2023-07-25T14:08:25.187590Z","shell.execute_reply":"2023-07-25T14:11:59.632232Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Training terms shape: \n(5363863, 3)\nGetting record IDs\n9248 Protein IDs found\nFetching Label Values\nEstablishing labels\nCreating Label-Protein Dictionary\nProcessing Label-Protein Dictionary\n","output_type":"stream"},{"name":"stderr","text":"100% (1500 of 1500) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n","output_type":"stream"},{"name":"stdout","text":"Getting sequences for training\nGetting sequences for testing\nComputing class weights\nCreating sampler based on class weights\nPutting training data into Data Loader\nPutting test data into Data Loader\nPreparing model\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"214.43935585021973\n","output_type":"stream"}]},{"cell_type":"code","source":"for i,data in enumerate(train_loader):\n    print(f'Step {i + 1}:')\n    print('=======')\n    print(f'Number of graphs in the current batch: {data.num_graphs}')\n    print(data)\n    print()\n    \n    if i > 10:\n        break","metadata":{"scrolled":true,"id":"oZkqGbCD1K4p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5e72260-62c8-4f50-e8b0-ce4a48944faa","execution":{"iopub.status.busy":"2023-07-25T14:11:59.635470Z","iopub.execute_input":"2023-07-25T14:11:59.635835Z","iopub.status.idle":"2023-07-25T14:12:00.751076Z","shell.execute_reply.started":"2023-07-25T14:11:59.635801Z","shell.execute_reply":"2023-07-25T14:12:00.749918Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Step 1:\n=======\nNumber of graphs in the current batch: 2048\nDataBatch(edge_index=[2, 458083], x=[40513, 33], edge_attr=[458083, 2], y=[2048, 1500], batch=[40513], ptr=[2049])\n\nStep 2:\n=======\nNumber of graphs in the current batch: 2048\nDataBatch(edge_index=[2, 455410], x=[40469, 33], edge_attr=[455410, 2], y=[2048, 1500], batch=[40469], ptr=[2049])\n\nStep 3:\n=======\nNumber of graphs in the current batch: 2048\nDataBatch(edge_index=[2, 451488], x=[40493, 33], edge_attr=[451488, 2], y=[2048, 1500], batch=[40493], ptr=[2049])\n\nStep 4:\n=======\nNumber of graphs in the current batch: 2048\nDataBatch(edge_index=[2, 454036], x=[40499, 33], edge_attr=[454036, 2], y=[2048, 1500], batch=[40499], ptr=[2049])\n\nStep 5:\n=======\nNumber of graphs in the current batch: 1056\nDataBatch(edge_index=[2, 237461], x=[20901, 33], edge_attr=[237461, 2], y=[1056, 1500], batch=[20901], ptr=[1057])\n\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-07-25T14:12:00.755094Z","iopub.execute_input":"2023-07-25T14:12:00.755429Z","iopub.status.idle":"2023-07-25T14:12:01.326925Z","shell.execute_reply.started":"2023-07-25T14:12:00.755396Z","shell.execute_reply":"2023-07-25T14:12:01.325946Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"if notebook_run:\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = GraphGAT(in_channels=num_features,hidden_dim=128,num_layers=3,out_channels=num_classes,dropout=0.05,act='selu').to(device)\n    #model = GraphSAGE(num_features, 256, num_classes).to(device)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\nloss_function = torch.nn.MultiLabelSoftMarginLoss(weight = class_weights.to(device) )\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\naccuracy = MultilabelAccuracy(num_labels=1500).to(device)\nmlss = MultilabelStatScores(1500, average='macro').to(device)\n\ndef train():\n    model.train()\n\n    correct = 0\n    total_loss = 0\n    for i,data in enumerate(train_loader):\n        optimizer.zero_grad()\n        data = data.to(device)\n        logits, out = model(data)\n        loss = loss_function(out, data.y)\n        loss.backward()  # Backward pass (calculate gradients)\n\n        # Gradient clipping\n        max_gradient_norm = 1.0  # Set the maximum gradient norm value\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n        optimizer.step()\n        \n        total_loss += loss\n            \n    # After the training loop ends, there might be gradients that are not yet updated\n    # So, you should perform an optimization step outside the loop to update those gradients\n    max_gradient_norm = 1.0  # Set the maximum gradient norm value\n    torch.nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n    optimizer.step()\n\n\n    return total_loss / (i+1)  # Derive ratio of correct predictions.\n\ndef test(data_loader, verbose=True):\n    model.eval()\n\n    all_preds = []\n    all_labels = []\n    total_acc = 0\n    clear_output(wait=True)\n    running_vloss = 0.0\n\n    with torch.no_grad():\n        for i,data in enumerate(data_loader):\n            data = data.to(device)\n            logits, out = model(data)\n            vloss = loss_function(out, data.y)\n            total_acc += accuracy(out,data.y)\n            running_vloss += vloss\n            all_preds.extend(out.cpu().numpy())\n            all_labels.extend(data.y.cpu().numpy())\n\n    avg_vloss = running_vloss / (i + 1)\n    avg_acc = total_acc/(i+1)\n    if verbose:\n        result = calculate_metrics(np.array(all_preds), np.array(all_labels))\n        print(\"epoch:{:2d} fold:{:3d} test: \"\n              \"micro f1: {:.3f} \"\n              \"macro f1: {:.3f} \"\n              \"samples f1: {:.3f}\".format(epoch, k,\n                                          result['micro/f1'],\n                                          result['macro/f1'],\n                                          result['samples/f1']))\n    return avg_vloss, avg_acc\n\n    \nnum_folds = 1\nnum_epochs = 150\n\nlosses = []\nvlosses = []\ntest_accs = []\nepochs = []\nfold_epochs = []\nfor k in range(1,num_folds+1):\n    # Variables for early stopping\n    best_val_metric = float('inf')  # Or any large value if using accuracy, set it to 0 instead\n    patience = 15  # Number of epochs without improvement before stopping\n    epochs_without_improvement = 0\n\n    print(\"Fold: \" + str(k))\n    for epoch in range(1, num_epochs+1):\n        start = time.time()\n        loss = train().detach().cpu()\n        vloss, test_acc = test(test_loader)\n        end = time.time()\n        scheduler.step(vloss)\n        vloss = vloss.detach().cpu()\n        test_acc = test_acc.detach().cpu()\n        \n        # Check for early stopping\n        if vloss < best_val_metric:\n            best_val_metric = vloss\n            epochs_without_improvement = 0\n        else:\n            epochs_without_improvement += 1\n\n        if epochs_without_improvement >= patience:\n            print(\"Early stopping triggered!\")\n            break\n        \n        # Update the loss, test_acc, and epochs variables\n        losses.append(loss)\n        vlosses.append(vloss)\n        test_accs.append(test_acc)\n        epochs.append(epoch)\n        fold_epochs.append(str(k) + '.' + str(epoch))\n        \n        # Plot the updated data\n        plt.plot(fold_epochs, losses, label='Loss')\n        plt.plot(fold_epochs, vlosses, label='Validation Loss')\n\n        # Add labels and a legend to the plot\n        plt.xlabel('Fold.Epoch')\n        plt.ylabel('Value')\n        plt.legend()\n\n        # Label the last loss and test_acc values\n        last_loss = round(losses[-1].numpy().tolist(), 4)\n        last_vloss = round(vlosses[-1].numpy().tolist(), 4)\n        last_acc = round(test_accs[-1].numpy().tolist(), 4)\n        plt.text(fold_epochs[-1], losses[-1], f'{last_loss}', ha='right', va='bottom')\n        plt.text(fold_epochs[-1], vlosses[-1], f'{last_vloss}', ha='right', va='bottom')\n        # Show the plot\n        plt.show()\n        \n        plt.figure(figsize=(12,12))\n        plt.plot(fold_epochs, test_accs, label=\"Test Accuracy\")\n        plt.xlabel('Fold.Epoch')\n        plt.ylabel('Accuracy')\n        plt.text(fold_epochs[-1], test_accs[-1], f'{last_acc}', ha='right', va='bottom')\n        plt.show()\n        \n        print(\"Fold: \" + str(k))\n        print(f'Epoch: {epoch:03d}, Train Loss: {loss:e}, Validation Loss: {vloss:e} Validation Acc: {test_acc:e}, Time: {end-start:.4f}')\n    if k < num_folds:\n        train_loader, test_loader = prepare_training_data_and_models(sample_data_size=10000, just_data=True)\n\ntorch.save(model, 'gcm.torch')\ndel train_loader\ndel test_loader","metadata":{"id":"AykYOE5u1K4p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d782a1f0-728a-415e-ca0d-1313c4b42760","execution":{"iopub.status.busy":"2023-07-25T14:12:01.329087Z","iopub.execute_input":"2023-07-25T14:12:01.329661Z","iopub.status.idle":"2023-07-25T14:13:43.241046Z","shell.execute_reply.started":"2023-07-25T14:12:01.329627Z","shell.execute_reply":"2023-07-25T14:13:43.238957Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m97\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m epoch \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m1\u001b[0m, num_epochs+\u001b[94m1\u001b[0m):                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   \u001b[0mstart = time.time()                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   \u001b[0mloss = train().detach().cpu()                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   \u001b[0mvloss, test_acc = test(test_loader)                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   \u001b[0mend = time.time()                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   \u001b[0mscheduler.step(vloss)                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   \u001b[0mvloss = vloss.detach().cpu()                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mtest\u001b[0m:\u001b[94m68\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   \u001b[0mavg_vloss = running_vloss / (i + \u001b[94m1\u001b[0m)                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m\u001b[2m│   \u001b[0mavg_acc = total_acc/(i+\u001b[94m1\u001b[0m)                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 67 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m verbose:                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 68 \u001b[2m│   │   \u001b[0mresult = calculate_metrics(np.array(all_preds), np.array(all_labels))              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mepoch:\u001b[0m\u001b[33m{:2d}\u001b[0m\u001b[33m fold:\u001b[0m\u001b[33m{:3d}\u001b[0m\u001b[33m test: \u001b[0m\u001b[33m\"\u001b[0m                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 70 \u001b[0m\u001b[2m│   │   │     \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmicro f1: \u001b[0m\u001b[33m{:.3f}\u001b[0m\u001b[33m \u001b[0m\u001b[33m\"\u001b[0m                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   │     \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmacro f1: \u001b[0m\u001b[33m{:.3f}\u001b[0m\u001b[33m \u001b[0m\u001b[33m\"\u001b[0m                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mcalculate_metrics\u001b[0m:\u001b[94m222\u001b[0m                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mmicro/recall\u001b[0m\u001b[33m'\u001b[0m: recall_score(y_true=target, y_pred=pred, average=\u001b[33m'\u001b[0m\u001b[33mmicro\u001b[0m\u001b[33m'\u001b[0m),     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mmicro/f1\u001b[0m\u001b[33m'\u001b[0m: f1_score(y_true=target, y_pred=pred, average=\u001b[33m'\u001b[0m\u001b[33mmicro\u001b[0m\u001b[33m'\u001b[0m),             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m221 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mmacro/precision\u001b[0m\u001b[33m'\u001b[0m: precision_score(y_true=target, y_pred=pred, average=\u001b[33m'\u001b[0m\u001b[33mmacr\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m222 \u001b[2m│   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mmacro/recall\u001b[0m\u001b[33m'\u001b[0m: recall_score(y_true=target, y_pred=pred, average=\u001b[33m'\u001b[0m\u001b[33mmacro\u001b[0m\u001b[33m'\u001b[0m),     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mmacro/f1\u001b[0m\u001b[33m'\u001b[0m: f1_score(y_true=target, y_pred=pred, average=\u001b[33m'\u001b[0m\u001b[33mmacro\u001b[0m\u001b[33m'\u001b[0m),             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m224 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33msamples/precision\u001b[0m\u001b[33m'\u001b[0m: precision_score(y_true=target, y_pred=pred, average=\u001b[33m'\u001b[0m\u001b[33msa\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33msamples/recall\u001b[0m\u001b[33m'\u001b[0m: recall_score(y_true=target, y_pred=pred, average=\u001b[33m'\u001b[0m\u001b[33msamples\u001b[0m\u001b[33m'\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/\u001b[0m\u001b[1;33m_classification.py\u001b[0m:\u001b[94m2098\u001b[0m in \u001b[92mrecall_score\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2095 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m>>> recall_score(y_true, y_pred, average=None)\u001b[0m                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2096 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33marray([1. , 1. , 0.5])\u001b[0m                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2097 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2098 \u001b[2m│   \u001b[0m_, r, _, _ = precision_recall_fscore_support(                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2099 \u001b[0m\u001b[2m│   │   \u001b[0my_true,                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2100 \u001b[0m\u001b[2m│   │   \u001b[0my_pred,                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2101 \u001b[0m\u001b[2m│   │   \u001b[0mlabels=labels,                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/\u001b[0m\u001b[1;33m_classification.py\u001b[0m:\u001b[94m1577\u001b[0m in               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mprecision_recall_fscore_support\u001b[0m                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1574 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1575 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1576 \u001b[0m\u001b[2m│   \u001b[0msamplewise = average == \u001b[33m\"\u001b[0m\u001b[33msamples\u001b[0m\u001b[33m\"\u001b[0m                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1577 \u001b[2m│   \u001b[0mMCM = multilabel_confusion_matrix(                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1578 \u001b[0m\u001b[2m│   │   \u001b[0my_true,                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1579 \u001b[0m\u001b[2m│   │   \u001b[0my_pred,                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1580 \u001b[0m\u001b[2m│   │   \u001b[0msample_weight=sample_weight,                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/\u001b[0m\u001b[1;33m_classification.py\u001b[0m:\u001b[94m489\u001b[0m in                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mmultilabel_confusion_matrix\u001b[0m                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2;33m│   │      \u001b[0m\u001b[33m[[2, 1],\u001b[0m                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 487 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33m[1, 2]]])\u001b[0m                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 489 \u001b[2m│   \u001b[0my_type, y_true, y_pred = _check_targets(y_true, y_pred)                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m sample_weight \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 491 \u001b[0m\u001b[2m│   │   \u001b[0msample_weight = column_or_1d(sample_weight)                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 492 \u001b[0m\u001b[2m│   \u001b[0mcheck_consistent_length(y_true, y_pred, sample_weight)                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/\u001b[0m\u001b[1;33m_classification.py\u001b[0m:\u001b[94m87\u001b[0m in \u001b[92m_check_targets\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  84 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33my_pred : array or indicator matrix\u001b[0m                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  85 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  86 \u001b[0m\u001b[2m│   \u001b[0mcheck_consistent_length(y_true, y_pred)                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  87 \u001b[2m│   \u001b[0mtype_true = type_of_target(y_true, input_name=\u001b[33m\"\u001b[0m\u001b[33my_true\u001b[0m\u001b[33m\"\u001b[0m)                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  88 \u001b[0m\u001b[2m│   \u001b[0mtype_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[0m\u001b[33my_pred\u001b[0m\u001b[33m\"\u001b[0m)                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  89 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m  90 \u001b[0m\u001b[2m│   \u001b[0my_type = {type_true, type_pred}                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sklearn/utils/\u001b[0m\u001b[1;33mmulticlass.py\u001b[0m:\u001b[94m309\u001b[0m in \u001b[92mtype_of_target\u001b[0m        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m306 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m sparse_pandas:                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m307 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33my cannot be class \u001b[0m\u001b[33m'\u001b[0m\u001b[33mSparseSeries\u001b[0m\u001b[33m'\u001b[0m\u001b[33m or \u001b[0m\u001b[33m'\u001b[0m\u001b[33mSparseArray\u001b[0m\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m)              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m308 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m309 \u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m is_multilabel(y):                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m310 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mmultilabel-indicator\u001b[0m\u001b[33m\"\u001b[0m                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m311 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m312 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[0m                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sklearn/utils/\u001b[0m\u001b[1;33mmulticlass.py\u001b[0m:\u001b[94m191\u001b[0m in \u001b[92mis_multilabel\u001b[0m         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m188 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (y.dtype.kind \u001b[95min\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mbiu\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mor\u001b[0m _is_integral_float(labels))  \u001b[2m# bool, int, uint\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m189 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m191 \u001b[2m│   │   \u001b[0mlabels = xp.unique_values(y)                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m193 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mlen\u001b[0m(labels) < \u001b[94m3\u001b[0m \u001b[95mand\u001b[0m (                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[2m│   │   │   \u001b[0my.dtype.kind \u001b[95min\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mbiu\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mor\u001b[0m _is_integral_float(labels)  \u001b[2m# bool, int, uint\u001b[0m         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sklearn/utils/\u001b[0m\u001b[1;33m_array_api.py\u001b[0m:\u001b[94m84\u001b[0m in \u001b[92munique_values\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m numpy.unique(x, return_counts=\u001b[94mTrue\u001b[0m)                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 83 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92munique_values\u001b[0m(\u001b[96mself\u001b[0m, x):                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 84 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m numpy.unique(x)                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 85 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 86 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mconcat\u001b[0m(\u001b[96mself\u001b[0m, arrays, *, axis=\u001b[94mNone\u001b[0m):                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 87 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m numpy.concatenate(arrays, axis=axis)                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92munique\u001b[0m:\u001b[94m180\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/numpy/lib/\u001b[0m\u001b[1;33marraysetops.py\u001b[0m:\u001b[94m274\u001b[0m in \u001b[92munique\u001b[0m                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m271 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m272 \u001b[0m\u001b[2m│   \u001b[0mar = np.asanyarray(ar)                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m273 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m axis \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m274 \u001b[2m│   │   \u001b[0mret = _unique1d(ar, return_index, return_inverse, return_counts,                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m275 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mequal_nan=equal_nan)                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _unpack_tuple(ret)                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/numpy/lib/\u001b[0m\u001b[1;33marraysetops.py\u001b[0m:\u001b[94m336\u001b[0m in \u001b[92m_unique1d\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   \u001b[0mperm = ar.argsort(kind=\u001b[33m'\u001b[0m\u001b[33mmergesort\u001b[0m\u001b[33m'\u001b[0m \u001b[94mif\u001b[0m return_index \u001b[94melse\u001b[0m \u001b[33m'\u001b[0m\u001b[33mquicksort\u001b[0m\u001b[33m'\u001b[0m)               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0maux = ar[perm]                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m336 \u001b[2m│   │   \u001b[0mar.sort()                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m\u001b[2m│   │   \u001b[0maux = ar                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m\u001b[2m│   \u001b[0mmask = np.empty(aux.shape, dtype=np.bool_)                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[2m│   \u001b[0mmask[:\u001b[94m1\u001b[0m] = \u001b[94mTrue\u001b[0m                                                                        \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mKeyboardInterrupt\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">97</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> epoch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, num_epochs+<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>start = time.time()                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = train().detach().cpu()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 97 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>vloss, test_acc = test(test_loader)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>end = time.time()                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>scheduler.step(vloss)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>vloss = vloss.detach().cpu()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">test</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">68</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>avg_vloss = running_vloss / (i + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>avg_acc = total_acc/(i+<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> verbose:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 68 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>result = calculate_metrics(np.array(all_preds), np.array(all_labels))              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"epoch:{:2d} fold:{:3d} test: \"</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 70 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">\"micro f1: {:.3f} \"</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">\"macro f1: {:.3f} \"</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">calculate_metrics</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">222</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'micro/recall'</span>: recall_score(y_true=target, y_pred=pred, average=<span style=\"color: #808000; text-decoration-color: #808000\">'micro'</span>),     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'micro/f1'</span>: f1_score(y_true=target, y_pred=pred, average=<span style=\"color: #808000; text-decoration-color: #808000\">'micro'</span>),             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'macro/precision'</span>: precision_score(y_true=target, y_pred=pred, average=<span style=\"color: #808000; text-decoration-color: #808000\">'macr</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>222 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'macro/recall'</span>: recall_score(y_true=target, y_pred=pred, average=<span style=\"color: #808000; text-decoration-color: #808000\">'macro'</span>),     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'macro/f1'</span>: f1_score(y_true=target, y_pred=pred, average=<span style=\"color: #808000; text-decoration-color: #808000\">'macro'</span>),             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'samples/precision'</span>: precision_score(y_true=target, y_pred=pred, average=<span style=\"color: #808000; text-decoration-color: #808000\">'sa</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'samples/recall'</span>: recall_score(y_true=target, y_pred=pred, average=<span style=\"color: #808000; text-decoration-color: #808000\">'samples'</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sklearn/metrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_classification.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2098</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">recall_score</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2095 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">&gt;&gt;&gt; recall_score(y_true, y_pred, average=None)</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2096 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">array([1. , 1. , 0.5])</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2097 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2098 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_, r, _, _ = precision_recall_fscore_support(                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2099 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>y_true,                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2100 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>y_pred,                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2101 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>labels=labels,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sklearn/metrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_classification.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1577</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">precision_recall_fscore_support</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1574 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1575 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calculate tp_sum, pred_sum, true_sum ###</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1576 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>samplewise = average == <span style=\"color: #808000; text-decoration-color: #808000\">\"samples\"</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1577 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>MCM = multilabel_confusion_matrix(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1578 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>y_true,                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1579 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>y_pred,                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1580 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sample_weight=sample_weight,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sklearn/metrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_classification.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">489</span> in                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">multilabel_confusion_matrix</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │      </span><span style=\"color: #808000; text-decoration-color: #808000\">[[2, 1],</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 487 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">[1, 2]]])</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 489 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>y_type, y_true, y_pred = _check_targets(y_true, y_pred)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> sample_weight <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 491 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sample_weight = column_or_1d(sample_weight)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 492 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>check_consistent_length(y_true, y_pred, sample_weight)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sklearn/metrics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_classification.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">87</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_targets</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  84 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">y_pred : array or indicator matrix</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  85 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  86 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>check_consistent_length(y_true, y_pred)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  87 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>type_true = type_of_target(y_true, input_name=<span style=\"color: #808000; text-decoration-color: #808000\">\"y_true\"</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  88 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>type_pred = type_of_target(y_pred, input_name=<span style=\"color: #808000; text-decoration-color: #808000\">\"y_pred\"</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  89 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  90 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>y_type = {type_true, type_pred}                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sklearn/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">multiclass.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">309</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">type_of_target</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">306 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> sparse_pandas:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"y cannot be class 'SparseSeries' or 'SparseArray'\"</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">308 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>309 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_multilabel(y):                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">310 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"multilabel-indicator\"</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">311 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">312 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># DeprecationWarning will be replaced by ValueError, see NEP 34</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sklearn/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">multiclass.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">191</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">is_multilabel</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">188 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (y.dtype.kind <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"biu\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _is_integral_float(labels))  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># bool, int, uint</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>191 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>labels = xp.unique_values(y)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(labels) &lt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>y.dtype.kind <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"biu\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _is_integral_float(labels)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># bool, int, uint</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sklearn/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_array_api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">84</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unique_values</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> numpy.unique(x, return_counts=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 82 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 83 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unique_values</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 84 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> numpy.unique(x)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 85 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 86 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">concat</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, arrays, *, axis=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 87 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> numpy.concatenate(arrays, axis=axis)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unique</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">180</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/numpy/lib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arraysetops.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">274</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unique</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">271 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">272 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>ar = np.asanyarray(ar)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">273 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> axis <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>274 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ret = _unique1d(ar, return_index, return_inverse, return_counts,                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">275 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>equal_nan=equal_nan)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _unpack_tuple(ret)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/numpy/lib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arraysetops.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">336</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_unique1d</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">333 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>perm = ar.argsort(kind=<span style=\"color: #808000; text-decoration-color: #808000\">'mergesort'</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_index <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #808000; text-decoration-color: #808000\">'quicksort'</span>)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">334 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>aux = ar[perm]                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">335 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>336 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ar.sort()                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">337 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>aux = ar                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">338 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>mask = np.empty(aux.shape, dtype=np.bool_)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">339 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>mask[:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluate\n\nNow, we write some basic code to take a Networkx graph and predict the classes.","metadata":{"id":"jmEIO7Bj1K4r"}},{"cell_type":"code","source":"def predict_mult(ids, sequences, batch_size=4096, verbose=False):\n    protein_dataset = ProteinDataset(sequences, torch.zeros((len(ids),1500,1)), training=False)\n    loader = DataLoader(protein_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n    if verbose:\n        print(\"Evaluating sequences\")\n        print(\"Total sequences: \" + str(len(ids)))\n        \n    # Set the model to evaluation mode\n    model.eval()\n    \n    # Forward pass through the model\n    with torch.no_grad():\n        \n        for i,batch in enumerate(loader):\n            batch = batch.to(device)  # move batch to the device (GPU or CPU)\n            probs, outputs = model(batch)  # forward pass\n\n            # process the outputs (e.g., apply a threshold in case of binary classification, etc.)\n            batch_predictions = (outputs > 0.5).float()\n            if verbose:\n                print(\"Batch output \" + str(i) + \": \")\n                print(batch_predictions)\n                \n            yield ids[i*batch_size:(i+1)*batch_size], outputs.cpu().numpy(), batch_predictions.cpu().numpy()\n\n@lru_cache(maxsize=1024)  # Use None for unbounded cache size\ndef predict(sequence, verbose=False):\n    g = protein_recurrence_network(sequence)\n    # Convert the NetworkX graph to a PyTorch Geometric Data object\n    data = from_networkx_to_data(g, torch.zeros((1500,1)))\n    \n    if verbose:\n        print(\"Data: \")\n        print(data)\n\n    # Move data to the appropriate device\n    data = data.to(device)\n\n    # Set the model to evaluation mode\n    model.eval()\n\n    # Forward pass through the model\n    with torch.no_grad():\n        logits, output = model(data)\n        if verbose:\n            print(\"Model prediction: \")\n            print(output)\n\n    # The output is log-probabilities, use softmax to get probabilities\n    out_probs = output\n    \n    # In a multi-label classification, an element is considered to be predicted as '1'\n    # if its probability is greater than or equal to 0.5.\n    out_preds = (out_probs > 0.5).float()\n\n    return out_probs, out_preds","metadata":{"id":"x6g52g-i1K4s","execution":{"iopub.status.busy":"2023-07-25T14:13:43.244727Z","iopub.status.idle":"2023-07-25T14:13:43.245449Z","shell.execute_reply.started":"2023-07-25T14:13:43.245193Z","shell.execute_reply":"2023-07-25T14:13:43.245217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_seq = 'YAWVHDHCNWCLERVGTVHDEKWTMEDPMVPKHCECNEPIQAWTQDNDLYNFCITLQICANNNRDGGNLIGRVDQLALQKRLLDQNWHKNCTPPSVVTRCNCATCEEKVETRVHFMKIMGESGWDGWVMYLPLGQQICYSIPHRQHKCWWSIWFVDFRLLPIGERNDTLSCFMIIKLEWIFDVCHLHDKSIEIAEAGVQIQVWAQQICSGTYIEGWLDWENSPIACPDGDYWSNWTAMVVAFCECRKRMCSVIPQTKFYAFHMVHNKWWLQWFYTSHEGKKIVGIEYHQGSCYYKWTKGEKHMHMNVEQRQWGADQVVHTPFNAWACWMHTAKHGDCNVPGQHWGMGWFRDDDELAAYGHHTEHGDATQLLFGTCYVCPLNIVYLMGTLVLPRHQHVRNKRPMVDRDMVYTRDKIIQELVWHGSYYILRPLMMRNTQHIKYLVYRGFHSIPKKDIAQPKRRGNKVGDKHVWKQFWIGSQPNHSKNTLMDLWHSAFMKWCNDFPDEPTKYVAGWPNIHPMGLALCLHPPSPRREKWDKHMFTPDYDHMSSWPEFAAHMDDCWVHNTFQIPWFWPNHHGRFHAQNVFLVWFTTGIKAGLDLMNICMIWGDKPRTHKIIFHHMRDWKNHPIEFTMKMEEKYHWDGKFDYHLPFRYWDRMSIRHDNYKTSWPCGWPSWHYALIELTCYGEMEIYGWADQEYRQCDQTFHMQLQMQNMTKLIRWYTHLGCDSVMCVQSALHTLKEWKRPTRMIKNGLGLILNLMVMACAGHFTISDGFLLLESPWKWGNSYSGNSVEGILAVKGVDYDFDGDYAWEQRSNQQWVGGLMQCILAGLPRLNLEMFRQESMWANTYGMPSYKQTDFFHSNLIRTKRMDEMSHAMVRGWTGILVNFTHHNWTWYMSLLCQSAYGTARTIFTGGNPAADDNRDLDHEDDEVYDVWIDSECTAQWLSMPVGIPNYGFCTCQAKQWINRGIPAGKLFMEVCPWMNDNQKGASSHCYIIEWCS'\nt = predict(test_seq)\ndisplay(t)\ntest_seqs = ['YAWVHDHCNWCLERVGTVHDEKWTMEDPMVPKHCECNEPIQAWTQDNDLYNFCITLQICANNNRDGGNLIGRVDQLALQKRLLDQNWHKNCTPPSVVTRCNCATCEEKVETRVHFMKIMGESGWDGWVMYLPLGQQICYSIPHRQHKCWWSIWFVDFRLLPIGERNDTLSCFMIIKLEWIFDVCHLHDKSIEIAEAGVQIQVWAQQICSGTYIEGWLDWENSPIACPDGDYWSNWTAMVVAFCECRKRMCSVIPQTKFYAFHMVHNKWWLQWFYTSHEGKKIVGIEYHQGSCYYKWTKGEKHMHMNVEQRQWGADQVVHTPFNAWACWMHTAKHGDCNVPGQHWGMGWFRDDDELAAYGHHTEHGDATQLLFGTCYVCPLNIVYLMGTLVLPRHQHVRNKRPMVDRDMVYTRDKIIQELVWHGSYYILRPLMMRNTQHIKYLVYRGFHSIPKKDIAQPKRRGNKVGDKHVWKQFWIGSQPNHSKNTLMDLWHSAFMKWCNDFPDEPTKYVAGWPNIHPMGLALCLHPPSPRREKWDKHMFTPDYDHMSSWPEFAAHMDDCWVHNTFQIPWFWPNHHGRFHAQNVFLVWFTTGIKAGLDLMNICMIWGDKPRTHKIIFHHMRDWKNHPIEFTMKMEEKYHWDGKFDYHLPFRYWDRMSIRHDNYKTSWPCGWPSWHYALIELTCYGEMEIYGWADQEYRQCDQTFHMQLQMQNMTKLIRWYTHLGCDSVMCVQSALHTLKEWKRPTRMIKNGLGLILNLMVMACAGHFTISDGFLLLESPWKWGNSYSGNSVEGILAVKGVDYDFDGDYAWEQRSNQQWVGGLMQCILAGLPRLNLEMFRQESMWANTYGMPSYKQTDFFHSNLIRTKRMDEMSHAMVRGWTGILVNFTHHNWTWYMSLLCQSAYGTARTIFTGGNPAADDNRDLDHEDDEVYDVWIDSECTAQWLSMPVGIPNYGFCTCQAKQWINRGIPAGKLFMEVCPWMNDNQKGASSHCYIIEWCS','YAWVHDHCNVPKHCECNEPIQAWTQDNDLYNFCITLQICANNNRDGGNLIGRVDQLALQKRLLDQNWHKNCTPPSVVTRCNCATCEEKVETRVHFMKIMGESGWDGWVMYLPLGQQICYSIPHRQHKCWWSIWFVDFRLLPIGERNDTLSCFMIIKLEWIFDVCHLHDKSIEIAEAGVQIQVWAQQICSGTYIEGWLDWENSPIACPDGDYWSNWTAMVVAFCECRKRMCSVIPQTKFYAFHMVHNKWWLQWFYTSHEGKKIVGIEYHQGSCYYKWTKGEKHMHMNVEQRQWGADQVVHTPFNAWACWMHTAKHGDCNVPGQHWGMGWFRDDDELAAYGHHTEHGDATQLLFGTCYVCPLNIVYLMGTLVLPRHQHVRNKRPMVDRDMVYTRDKIIQELVWHGSYYILRPLMMRNTQHIKYLVYRGFHSIPKKDIAQPKRRGNKVGDKHVWKQFWIGSQPNHSKNTLMDLWHSAFMKWCNDFPDEPTKYVAGWPNIHPMGLALCLHPPSPRREKWDKHMFTPDYDHMSSWPEFAAHMDDCWVHNTFQIPWFWPNHHGRFHAQNVFLVWFTTGIKAGLDLMNICMIWGDKPRTHKIIFHHMRDWKNHPIEFTMKMEEKYHWDGKFDYHLPFRYWDRMSIRHDNYKTSWPCGWPSWHYALIELTCYGEMEIYGWADQEYRQCDQTFHMQLQMQNMTKLIRWYTHLGCDSVMCVQSALHTLKEWKRPTRMIKNGLGLILNLMVMACAGHFTISDGFLLLESPWKWGNSYSGNSVEGILAVKGVDYDFDGDYAWEQRSNQQWVGGLMQCILAGLPRLNLEMFRQESMWANTYGMPSYKQTDFFHSNLIRTKRMDEMSHAMVRGWTGILVNFTHHNWTWYMSLLCQSAYGTARTIFTGGNPAADDNRDLDHEDDEVYDVWIDSECTAQWLSMPVGIPNYGFCTCQAKQWINRGIPAGKLFMEVCPWMNDNQKGASSHCYIIEWCS']\nfor ids,probs,ts in predict_mult(['t1','t2'],test_seqs):\n    display(ids)\n    display(probs)\n    display(ts)","metadata":{"id":"t73eH9Tn1K4t","scrolled":true,"execution":{"iopub.status.busy":"2023-07-25T14:13:43.246786Z","iopub.status.idle":"2023-07-25T14:13:43.247504Z","shell.execute_reply.started":"2023-07-25T14:13:43.247248Z","shell.execute_reply":"2023-07-25T14:13:43.247271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(ts)","metadata":{"id":"7jqhlXTy1K4u","execution":{"iopub.status.busy":"2023-07-25T14:13:43.248750Z","iopub.status.idle":"2023-07-25T14:13:43.249465Z","shell.execute_reply.started":"2023-07-25T14:13:43.249208Z","shell.execute_reply":"2023-07-25T14:13:43.249231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.021665,"end_time":"2023-05-09T08:41:01.780867","exception":false,"start_time":"2023-05-09T08:41:01.759202","status":"completed"},"tags":[],"id":"NsMJWTki1K4w"}},{"cell_type":"markdown","source":"For submission we will use the protein embeddings of the test data created by [Sergei Fironov](https://www.kaggle.com/sergeifironov) using the Rost Lab's T5 protein language model.","metadata":{"papermill":{"duration":0.02075,"end_time":"2023-05-09T08:41:01.82296","exception":false,"start_time":"2023-05-09T08:41:01.80221","status":"completed"},"tags":[],"id":"zRulLIuJ1K4x"}},{"cell_type":"code","source":"# Parse the fasta file\nkaggle_input_embeds = '/kaggle/input/t5embeds'\ntest_protein_ids = set(np.load(kaggle_input_embeds + '/test_ids.npy'))\ntest_records = SeqIO.parse(kaggle_input_data + '/Test (Targets)/testsuperset.fasta', format='fasta')\n\ntest_results = predict_mult(*list(zip(*[(record.id, str(record.seq)) for record in test_records if record.id in test_protein_ids])), verbose=True)","metadata":{"papermill":{"duration":10.290827,"end_time":"2023-05-09T08:41:12.134919","exception":false,"start_time":"2023-05-09T08:41:01.844092","status":"completed"},"tags":[],"id":"NnNy1w7z1K4x","scrolled":true,"execution":{"iopub.status.busy":"2023-07-25T14:13:43.250724Z","iopub.status.idle":"2023-07-25T14:13:43.251438Z","shell.execute_reply.started":"2023-07-25T14:13:43.251183Z","shell.execute_reply":"2023-07-25T14:13:43.251206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the predictions we will create the submission data frame.\n\n**Note**: This will take atleast **15 to 20** minutes to finish.","metadata":{"id":"7EgfXYPY1K41"}},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/code/alexandervc/baseline-multilabel-to-multitarget-binary\ndf_submission = pd.DataFrame(\n    [(batch_ids[i], out_labels[ix], batch_probs[ix])\n    for batch_ids, batch_probs, batch_preds in test_results\n    for i in range(len(batch_ids))\n    for ix in np.nonzero(batch_preds[i])[0]], \n    columns=['Protein Id', 'GO Term Id', 'Prediction']\n)\ndf_submission.to_csv(\"submission.tsv\",header=False, index=False, sep=\"\\t\")","metadata":{"id":"kPp6NFlC1K42","scrolled":true,"execution":{"iopub.status.busy":"2023-07-25T14:13:43.252697Z","iopub.status.idle":"2023-07-25T14:13:43.253407Z","shell.execute_reply.started":"2023-07-25T14:13:43.253151Z","shell.execute_reply":"2023-07-25T14:13:43.253174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"papermill":{"duration":0.063739,"end_time":"2023-05-09T08:52:16.292974","exception":false,"start_time":"2023-05-09T08:52:16.229235","status":"completed"},"tags":[],"id":"-ZcOhlK61K42","execution":{"iopub.status.busy":"2023-07-25T14:13:43.254679Z","iopub.status.idle":"2023-07-25T14:13:43.255376Z","shell.execute_reply.started":"2023-07-25T14:13:43.255134Z","shell.execute_reply":"2023-07-25T14:13:43.255158Z"},"trusted":true},"execution_count":null,"outputs":[]}]}